{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to my homelab documentation","text":"<p>This is the third version of my homelab </p> <p>v1 : Personnal-docker-config v2 : Homelab-infra v3 : homelabv3-infra</p> <p>To start, I would like to thank all maintainers and contributors to open source projects that make my lab possible !</p>"},{"location":"#what-are-the-key-features","title":"What are the key features","text":"<ul> <li> Open source</li> <li> Dual stacks IPv4/IPv6</li> <li> Privacy</li> <li> Security</li> <li> PKI with certificates autorenew</li> <li> Monitoring, logging and alerting</li> <li> Offsite encrypted backup to S3 multi A-Z</li> <li> Manage everything except :<ul> <li> Emails</li> </ul> </li> <li> Eveything is automated with scripts, IaC, etc except :<ul> <li> Hypervisor installation but can be done with netboot.xyz</li> <li> Networking hardware device configuration (routers, switchs)</li> </ul> </li> </ul>"},{"location":"#roadmap","title":"Roadmap","text":"<ul> <li>Kubernetes :<ul> <li> Kubernetes node firewalling</li> <li> Kubernetes policies rules</li> </ul> </li> <li>Monitoring/Logging/Alerting :<ul> <li> Alerting system</li> </ul> </li> <li>Security :<ul> <li> Implement systemd-resolved dnssec validation (DS record not supported by my current registrar)</li> </ul> </li> </ul>"},{"location":"getting-started/","title":"Getting started","text":"<p>Install git and clone the project <pre><code>apt install -y git\ngit clone https://github.com/M0NsTeRRR/homelabv3-infra.git\n</code></pre></p> <p>Warning</p> <p>This guide assumes the following :</p> <ul> <li>You have configured an SSH agent with your SSH keys</li> <li>You have ghcr.io configured with a github token (needed for OCI helm chart) with Public Repositories (read-only) access (<code>cat ~/github_token.txt | docker login ghcr.io -u m0nsterrr --password-stdin</code>)</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#with-devcontainer-recommended","title":"with devcontainer recommended","text":"<ol> <li>Follow DevContainer documentation to install it</li> <li>Build the container</li> </ol> <p>Info</p> <ul> <li>Every files ending in <code>.crt</code> in <code>ssl</code> folders are copied to <code>/usr/local/share/ca-certificates</code> inside the devcontainer to validate PKI</li> <li>Every files in <code>~/.kube</code> of your current user will be copied to <code>/home/vscode/.kube</code> and exported to <code>$KUBECONFIG</code></li> </ul>"},{"location":"getting-started/installation/#with-binaries","title":"with binaries","text":"<ol> <li> <p>Install (versions are pinned in configuration files)</p> <ul> <li>Uv</li> <li>Task</li> <li>Packer</li> <li>Terraform</li> <li>Terragrunt</li> <li>Kubectl</li> <li>Kustomize</li> <li>Helm</li> <li>Helmfile</li> </ul> </li> <li> <p>Setup python</p> <pre><code>uv --sync-extras\n</code></pre> <p>Info</p> <p>Don't forget to source python environment when opening a new shell before doing anything</p> </li> <li> <p>Install root ca certificates on your machine</p> <pre><code>sudo cp ssl/*.crt /usr/local/share/ca-certificates\nsudo update-ca-certificates\n</code></pre> </li> <li> <p>Init packer plugins</p> <pre><code>cd packer\npacker init templates/ubuntu\n</code></pre> </li> <li> <p>Init terraform plugins</p> <pre><code>cd terraform/prod\nterragrunt run-all init\n</code></pre> </li> <li> <p>Install helm plugins</p> <pre><code>helm plugin install https://github.com/databus23/helm-diff\n</code></pre> </li> </ol>"},{"location":"getting-started/upgrade/","title":"Upgrade","text":""},{"location":"getting-started/upgrade/#with-devcontainer-recommended","title":"with devcontainer recommended","text":"<p>Just rebuild the container</p>"},{"location":"getting-started/upgrade/#with-binaries","title":"with binaries","text":"<ol> <li> <p>Update binaries</p> </li> <li> <p>Update python packages</p> <pre><code>source venv/bin/activate\npython3 -m pip install --upgrade pip\npip install --upgrade '.[ansible,terraform,octodns,documentation]'\n</code></pre> </li> <li> <p>Update packer plugins</p> <pre><code>cd packer\npacker init --upgrade templates/ubuntu\n</code></pre> </li> <li> <p>Update terraform plugins</p> <pre><code>cd terraform/prod\nterragrunt run-all init --upgrade\n</code></pre> </li> </ol>"},{"location":"guide/","title":"Guide","text":"<p>The following guides demonstrate use-cases and provide examples of how to use the project.</p>"},{"location":"guide/ansible/","title":"Ansible","text":""},{"location":"guide/ansible/#what-is-ansible","title":"What is Ansible ?","text":"<p>Ansible gives the ability to do software provisioning, configuration management, and application deployment functionality. It will allow us to deploy generic configuration to Packer template and applications.</p>"},{"location":"guide/ansible/#list-of-supported-distributions","title":"List of supported distributions","text":"<p>Version is pinned in configuration file.</p> <p>Distributions :</p> <ul> <li>Ubuntu</li> </ul>"},{"location":"guide/ansible/#usage","title":"Usage","text":""},{"location":"guide/ansible/#list-of-playbooks","title":"List of playbooks","text":"Playbook Description <code>deploy_infra.yml</code> Deploy application <code>deploy_packer.yml</code> Deploy generic configuration used by every VM <code>playbooks/add-ssh-keys.yml</code> Update fingerprints in <code>~/.ssh/known_hosts</code> from all hosts inventory <code>playbooks/generate-certs.yml</code> Generate certificate for a machine from PKI <code>playbooks/parted.yml</code> Grow last partition to fill all available spaces on disk"},{"location":"guide/ansible/#execute","title":"Execute","text":"<p>Configuration is stored in <code>ansible</code> folder.</p> <p>Fill <code>inventory.proxmox.yml</code> based on <code>inventory.proxmox.example</code>. Fill <code>ssl</code> folders with certificates. Fill <code>.vault_password.txt</code> at root with ansible vault password used. Fill all <code>secrets.yml</code> based on <code>secrets.example</code> in each subdirectory of <code>groups_vars</code>.</p> <p><code>PLAYBOOK</code> represents the playbook file used to deploy</p> <pre><code>cd ansible\nansible-playbook &lt;PLAYBOOK&gt;\n</code></pre> <p>KUBECONFIG environment variable is hardcoded to <code>/home/vscode/.kube/homelab</code> in <code>.devcontainer/Dockerfile</code> and context is set to <code>default</code> in <code>.devcontainer/postCreateCommand.sh</code></p> How to execute only a part of an ansible playbook ? <ul> <li> <p>Filter by hosts</p> <pre><code>-l SUBSET, --limit SUBSET # further limit selected hosts to an additional pattern\n</code></pre> </li> <li> <p>Filter by tags</p> <pre><code>-t TAGS, --tags TAGS # only run plays and tasks tagged with these values. This argument may be specified multiple times.\n</code></pre> </li> </ul>"},{"location":"guide/argocd/","title":"Argocd","text":""},{"location":"guide/argocd/#what-is-argocd","title":"What is Argocd ?","text":"<p>Argocd is a declarative, GitOps continuous delivery tool for Kubernetes.</p>"},{"location":"guide/argocd/#usage","title":"Usage","text":"<p>Configuration is stored in <code>argocd</code> folder.</p> <p>Nothing to do, configuration is deployed in the cluster from the Git repository.</p>"},{"location":"guide/ci_cd/","title":"CI/CD","text":""},{"location":"guide/ci_cd/#list-of-supported-cicd","title":"List of supported CI/CD","text":"<ul> <li>Github actions</li> </ul>"},{"location":"guide/ci_cd/#list-of-available-workflows","title":"List of available workflows","text":"Workflow Description <code>ansible-lint.yml</code> Lint Ansible configuration <code>doc.yml</code> Deploy generic configuration used by every VM <code>kubernetes-lint.yml</code> Lint Kubernetes configuration <code>octodns.yml</code> Lint Octodns and deploy Octodns configuration <code>packer-lint.yml</code> Lint Packer configuration <code>renovatebot-check.yml</code> Lint Renovatebot configuration <code>terraform-lint.yml</code> Lint Terraform and Terragrunt configuration"},{"location":"guide/ci_cd/#usage","title":"Usage","text":"<p>Workflows are stored in <code>.github/workflows</code> folder.</p> <p>Configure the following repository secrets in <code>Actions secrets and variables</code> :</p> <ul> <li><code>SCALEWAY_SECRET_KEY</code></li> </ul>"},{"location":"guide/ci_cd/#kube-lint","title":"Kube-lint","text":"<p>Configuration is stored at root as <code>.kube-linter.yaml</code></p>"},{"location":"guide/ci_cd/#documentation","title":"Documentation","text":"<p>Configuration is stored at root as <code>mkdocs.yml</code></p>"},{"location":"guide/dns_blocklist/","title":"DNS Blocklist","text":"<p>In addition to uBlock Origins  for Firefox , some devices, such as the YouTube app on my Android TV, do not use Firefox, so I've added a DNS blocklist to restrict trackers.</p>"},{"location":"guide/dns_blocklist/#how-its-setup","title":"How it's setup ?","text":"<p>Every day at 00:00, a systemd unit timer is triggered, which downloads a list of <code>RPZ</code> files from a text file located at <code>/etc/powerdns/rpz-sync.txt</code>. The files are then placed in the <code>/etc/powerdns/rpz</code> folder, and the Lua configuration is reloaded using the command <code>/usr/bin/rec_control reload-lua-config /etc/powerdns/recursor-rpz.lua</code>.</p>"},{"location":"guide/dns_blocklist/#blocklist-used","title":"Blocklist used","text":"<ul> <li>Github hagezi/dns-blocklists </li> </ul>"},{"location":"guide/kubernetes/","title":"Kubernetes","text":""},{"location":"guide/kubernetes/#what-is-kubernetes","title":"What is Kubernetes ?","text":"<p>Kubernetes also known as K8s, is an open source system for automating deployment, scaling, and management of containerized applications.</p>"},{"location":"guide/kubernetes/#usage","title":"Usage","text":""},{"location":"guide/kubernetes/#task","title":"Task","text":"<p>Use <code>uv run task --list</code> to find Kubernetes group recipes for deploying the base infrastructure until ArgoCD can take over.</p>"},{"location":"guide/octodns/","title":"Octodns","text":""},{"location":"guide/octodns/#what-is-octodns","title":"What is Octodns ?","text":"<p>Octodns gives the ability to manage DNS agnostically across multiple providers.</p>"},{"location":"guide/octodns/#list-of-supported-providers","title":"List of supported providers","text":"<ul> <li>Scaleway</li> </ul>"},{"location":"guide/octodns/#usage","title":"Usage","text":""},{"location":"guide/octodns/#internal","title":"Internal","text":"<p>Configuration is stored in <code>octodns/internal</code> folder.</p> <p><code>POWERDNS_API_KEY</code> represents the API token to manage your DNS zone</p> <pre><code>export POWERDNS_API_KEY=&lt;POWERDNS_API_KEY&gt;\nuv run task octodns:sync-internal\n</code></pre>"},{"location":"guide/octodns/#external","title":"External","text":"<p>You should not normally use it by hand it's running in a Github action.</p> <p>Configuration is stored in <code>octodns/external</code> folder.</p> <p><code>SCALEWAY_SECRET_KEY</code> represents the API token to manage your DNS zone</p> <pre><code>export SCALEWAY_SECRET_KEY=&lt;SCALEWAY_SECRET_KEY&gt;\nuv run task octodns:sync-external\n</code></pre>"},{"location":"guide/packer/","title":"Packer","text":""},{"location":"guide/packer/#what-is-packer","title":"What is Packer ?","text":"<p>Packer gives the ability to automate image builds. It will allow us to create customized template with pre-defined generic configuration.</p>"},{"location":"guide/packer/#list-of-supported-configuration","title":"List of supported configuration","text":"<p>Version is pinned in configuration file.</p> <p>Hypervisors:</p> <ul> <li>Proxmox</li> </ul> <p>Distributions :</p> <ul> <li>Ubuntu</li> </ul>"},{"location":"guide/packer/#how-does-it-works","title":"How does it works ?","text":"<pre><code>sequenceDiagram\n    actor User\n    User-&gt;&gt;Packer: Launch packer command\n    Packer-&gt;&gt;Hypervisor: Connect to hypervisor API&lt;br&gt;and ask hypervisor to create VM\n    create participant VM\n    Hypervisor-&gt;&gt;VM: Create and start VM\n    Packer-&gt;&gt;VM: Typing boot sequence&lt;br&gt;and tell the VM to connect to Packer HTTP server&lt;br&gt;to get cloud init configuration\n    Packer-&gt;&gt;Packer: Start HTTP server&lt;br&gt;and serve rendered cloud init configuration template&lt;br&gt;(minimal configuration)\n    VM-&gt;&gt;Packer: Download configuration through HTTP\n    VM-&gt;&gt;VM: Proceed to autoinstall&lt;br&gt;and reboot at the end\n    Packer-&gt;&gt;Packer: Waiting availability of SSH server\n    Packer-&gt;&gt;VM: SSH to the VM&lt;br&gt; and wait end of cloud init execution\n    Packer-&gt;&gt;VM: Execute ansible playbook deploy_packer.yml&lt;br&gt;to finish VM configuration\n    Packer-&gt;&gt;Packer: Shutdown VM,&lt;br&gt;remove CD-ROM,&lt;br&gt;convert VM to template&lt;br&gt;and stop HTTP server</code></pre>"},{"location":"guide/packer/#how-to-openclose-ports","title":"How to open/close ports ?","text":"<p><code>PORT</code> represents the packer http server port</p> <ul> <li> <p>Open port</p> IptablesUfw <pre><code>iptables -A INPUT -p tcp --dport &lt;PORT&gt; -j ACCEPT -m comment --comment \"Packer\"\n</code></pre> <pre><code>ufw allow &lt;PORT&gt;/tcp comment \"Packer\"\n</code></pre> </li> <li> <p>Close port</p> IptablesUfw <pre><code>iptables -D INPUT -p tcp --dport &lt;PORT&gt; -j ACCEPT -m comment --comment \"Packer\"\n</code></pre> <pre><code>ufw delete allow &lt;PORT&gt;/tcp\n</code></pre> </li> </ul> How to expose packer HTTP server from WSL ? <p><code>WINDOWS IP</code> represents the IP used to connect <code>WINDOWS PORT</code> represents the port used to connect <code>WSL_IP</code> represents the packer http server ip that will be accessible through <code>&lt;WINDOWS IP&gt;:&lt;WINDOWS PORT&gt;</code> <code>WSL PORT</code> represents the packer http server port that will be accessible through <code>&lt;WINDOWS IP&gt;:&lt;WINDOWS PORT&gt;</code> </p> <ul> <li> <p>To create a port forwarding rule open powershell prompt with admin right</p> <pre><code>New-NetFirewallRule -DisplayName 'Packer' -Direction Inbound -Protocol TCP -LocalPort &lt;WINDOWS PORT&gt; -Action Allow\nnetsh interface portproxy add v4tov4 listenaddress=&lt;WINDOWS IP&gt; connectaddress=&lt;WSL_IP&gt; listenport=&lt;WINDOWS PORT&gt; connectport=&lt;WSL PORT&gt;\n</code></pre> </li> <li> <p>To delete a port forwarding rule open powershell prompt with admin right</p> <pre><code>Remove-NetFirewallRule -DisplayName 'Packer'\nnetsh interface portproxy del v4tov4 listenaddress=&lt;WINDOWS IP&gt; listenport=&lt;WINDOWS PORT&gt;\n</code></pre> </li> </ul>"},{"location":"guide/packer/#usage","title":"Usage","text":"<p>Configuration is stored in <code>packer</code> folder.</p> <p>Packer use 8888/tcp port for this HTTP server.</p> <p><code>PROXMOX_PASSWORD</code> represents the proxmox password used for HTTP API</p> <p>Init plugins</p> <pre><code>uv run task packer:init\n</code></pre> <p>Generate ubuntu template <pre><code>uv run task packer:ubuntu\n</code></pre></p>"},{"location":"guide/proxmox_acme/","title":"Proxmox acme","text":""},{"location":"guide/proxmox_acme/#what-is-proxmox","title":"What is Proxmox ?","text":"<p>Proxmox Virtual Environment is a complete open-source platform for enterprise virtualization. With the built-in web interface you can easily manage VMs and containers, software-defined storage and networking, high-availability clustering, and multiple out-of-the-box tools using a single solution.</p>"},{"location":"guide/proxmox_acme/#how-to-enable-proxmox-acme","title":"How to enable Proxmox ACME ?","text":"<p>In this guide we will see how to enable proxmox ACME with vault. This guide assume vault PKI is already setup using the ansible role from this repository. This guide also assume that your proxmox server trust the vault PKI.</p> <ul> <li><code>email_account</code> with your email account (not used)</li> <li><code>vault_acme_url</code> like <code>https://vault.unicornafk.fr:8200/v1/pki/acme/directory</code></li> <li><code>proxmox_domains</code> it's a list of domains separated by <code>;</code> like <code>server.unicornafk.fr;server1.unicornafk.fr</code>. As we are using DNS round robin (recommended way to get cluster metrics) on proxmox exporter we must have an entry matching that record <code>server.unicornafk.fr</code></li> </ul> <p>Execute the following steps :</p> <ol> <li>SSH to a proxmox node</li> <li>Run <code>pvenode acme account register default &lt;email_acount&gt;</code></li> <li>Choose option 2 as we are using a custom endpoint</li> <li>Type your <code>&lt;vault_acme_url&gt;</code> and don't use external account binding.</li> <li>Configure ACME hostname <code>pvenode config set --acme domains=\"&lt;proxmox_domains&gt;\"</code></li> <li>Order a certificate <code>pvenode acme cert order</code></li> </ol> <p>Repeat step <code>5</code> to <code>6</code> on each server as step <code>1</code> to <code>4</code> need to be run only the first time on one node.</p> <p>If you need to delete a registered account when the ACME Server is not available <code>/etc/pve/priv/acme/default</code></p>"},{"location":"guide/proxmox_exporter/","title":"proxmox-exporter","text":"<p>Proxmox Exporter this is an exporter that exposes information gathered from Proxmox VE node for use by the Prometheus monitoring system.</p>"},{"location":"guide/proxmox_exporter/#how-to-create-a-supervision-user","title":"How to create a supervision user ?","text":"<ol> <li>Login to a proxmox node through web ui.</li> <li>Go to Datacenter &gt; Permissions &gt; Users</li> <li>Create an user</li> <li>Go to Datacenter &gt; Permissions</li> <li>Assign to the new user the <code>PVEAuditor</code> role</li> </ol> <p>Configure proxmox-exporter config to use the appropriate crendentials</p>"},{"location":"guide/renovatebot/","title":"Renovatebot","text":""},{"location":"guide/renovatebot/#what-is-renovatebot","title":"What is Renovatebot ?","text":"<p>Renovatebot is an universal dependency update tool that fits into your workflows.</p>"},{"location":"guide/renovatebot/#usage","title":"Usage","text":"<p>Configuration is stored in <code>.github/renovate.json5</code> file.</p> <p>Install the Github application in your git repository</p> <p>Nothing more to do, the application use the configuration from the Git repository.</p>"},{"location":"guide/s3/","title":"S3","text":""},{"location":"guide/s3/#acl-for-backup-bucket","title":"ACL for backup bucket","text":"<p>Replace <code>&lt;bucket_name&gt;</code> in the json below.</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:*\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::&lt;bucket_name&gt;/*\"\n            ]\n        }\n    ]\n}\n</code></pre>"},{"location":"guide/snmp_exporter/","title":"snmp-exporter","text":"<p>SNMP Exporter this exporter is the recommended way to expose SNMP data in a format which Prometheus can ingest.</p>"},{"location":"guide/snmp_exporter/#how-to-generate-snmp-exporter-configuration","title":"How to generate snmp-exporter configuration ?","text":"<p>SNMP v3 must be enabled and configured on all devices.</p> <p>Download the mib files :</p> <ul> <li>Mikrotik mib</li> <li>Brocade</li> <li>Qnap : Go to Control Panel &gt; Network &amp; File Services &gt; SNMP and Under SNMP MIB, click Download.</li> </ul> <p>Don't forget to change in the following configuration :</p> <ul> <li><code>&lt;snmp_exporter_username&gt;</code></li> <li><code>&lt;snmp_exporter_pass&gt;</code></li> <li><code>&lt;snmp_exporter_private&gt;</code></li> </ul> snmp-generator.yml<pre><code>---\nauths:\n  homelab_aes:\n    version: 3\n    username: \"&lt;snmp_exporter_username&gt;\"\n    password: \"&lt;snmp_exporter_pass&gt;\"\n    security_level: authPriv\n    auth_protocol: SHA\n    priv_protocol: AES\n    priv_password: \"&lt;snmp_exporter_private&gt;\"\n  homelab_des:\n    version: 3\n    username: \"&lt;snmp_exporter_username&gt;\"\n    password: \"&lt;snmp_exporter_pass&gt;\"\n    security_level: authPriv\n    auth_protocol: SHA\n    priv_protocol: DES\n    priv_password: \"&lt;snmp_exporter_private&gt;\"\nmodules:\n  # Default IF-MIB interfaces table with ifIndex.\n  if_mib:\n    walk: \n      - 1.3.6.1.2.1.1.3 # sysUpTime\n      - 1.3.6.1.2.1.2 # interfaces\n      - 1.3.6.1.2.1.31.1.1 # ifXTable\n    lookups:\n      - source_indexes: [ifIndex]\n        lookup: ifAlias\n      - source_indexes: [ifIndex]\n        lookup: ifDescr\n      - source_indexes: [ifIndex]\n        lookup: 1.3.6.1.2.1.31.1.1.1.1\n\n  # Mikrotik CCR2004-1g-12s+2xs\n  mikrotik:\n    walk:\n      - 1.3.6.1.2.1.1.3 # sysUpTime\n      - 1.3.6.1.2.1.2 # interfaces\n      - 1.3.6.1.2.1.31.1.1 # ifXTable\n      - 1.3.6.1.4.1.14988 # mikrotik\n    lookups:\n      - source_indexes: [ifIndex]\n        lookup: ifAlias\n      - source_indexes: [ifIndex]\n        lookup: ifDescr\n      - source_indexes: [ifIndex]\n        lookup: 1.3.6.1.2.1.31.1.1.1.1\n\n  # Brocade ICX 6450-24P &amp; ICX 7150-C12P\n  brocade:\n    walk:\n      - 1.3.6.1.2.1.1.3 # sysUpTime\n      - 1.3.6.1.2.1.2 # interfaces\n      - 1.3.6.1.2.1.31.1.1 # ifXTable\n      - 1.3.6.1.4.1.1991.1.1.2.1.11 # snAgImgVer\n      - 1.3.6.1.4.1.1991.1.1.1.2 # snChasPwr\n      - 1.3.6.1.4.1.1991.1.1.1.3 # snChasFan\n      - 1.3.6.1.4.1.1991.1.1.2.11 # snAgentCpu\n      - 1.3.6.1.4.1.1991.1.1.2.1.53 # snAgentMemUtil\n      - 1.3.6.1.4.1.1991.1.1.2.13 # snAgentTemp\n    lookups:\n      - source_indexes: [ifIndex]\n        lookup: ifAlias\n      - source_indexes: [ifIndex]\n        lookup: ifDescr\n      - source_indexes: [ifIndex]\n        lookup: 1.3.6.1.2.1.31.1.1.1.1\n\n  # Qnap TS-219 PII\n  qnap:\n    walk:\n      - 1.3.6.1.2.1.1.3 # sysUpTime\n      - 1.3.6.1.2.1.2 # interfaces\n      - 1.3.6.1.2.1.31.1.1 # ifXTable\n      - 1.3.6.1.4.1.24681.1.2.1 #qnap\n      - 1.3.6.1.4.1.24681.1.2.2 #qnap\n      - 1.3.6.1.4.1.24681.1.2.3 #qnap\n      - 1.3.6.1.4.1.24681.1.2.4 #qnap\n      - 1.3.6.1.4.1.24681.1.2.5 #qnap\n      - 1.3.6.1.4.1.24681.1.2.6 #qnap\n      - 1.3.6.1.4.1.24681.1.2.10 #qnap\n      - 1.3.6.1.4.1.24681.1.2.11 #qnap\n      - 1.3.6.1.4.1.24681.1.2.12 #qnap\n      - 1.3.6.1.4.1.24681.1.2.13 #qnap\n      - 1.3.6.1.4.1.24681.1.2.14 #qnap\n      - 1.3.6.1.4.1.24681.1.2.15 #qnap\n      - 1.3.6.1.4.1.24681.1.2.16 #qnap\n      - 1.3.6.1.4.1.24681.1.2.17 #qnap\n      - 1.3.6.1.4.1.24681.1.3 #qnap\n      - 1.3.6.1.4.1.24681.1.4 #qnap\n    lookups:\n      - source_indexes: [ifIndex]\n        lookup: ifAlias\n      - source_indexes: [ifIndex]\n        lookup: ifDescr\n      - source_indexes: [ifIndex]\n        lookup: 1.3.6.1.2.1.31.1.1.1.1\n      - source_indexes: [hdIndex]\n        lookup: hdDescr\n</code></pre> <p>Follow instructions step from snmp-exporter documentation</p> <p>Configure snmp-exporter config to use the appropriate crendentials</p>"},{"location":"guide/terraform/","title":"Terraform","text":""},{"location":"guide/terraform/#what-is-terraform","title":"What is Terraform ?","text":"<p>Terraform gives the ability to automate provision and to manage resources in any cloud or data center in a stateful manner. It will allow us to deploy virtual machine from a customized packer template with pre-defined generic configuration.</p>"},{"location":"guide/terraform/#what-is-terragrunt","title":"What is Terragrunt ?","text":"<p>Terragrunt is a thin wrapper that provides extra tools for keeping your configurations DRY, working with multiple Terraform modules, and managing remote state.</p>"},{"location":"guide/terraform/#list-of-supported-configuration","title":"List of supported configuration","text":"<p>Version is pinned in configuration file.</p> <p>Hypervisors:</p> <ul> <li>Proxmox</li> </ul> <p>DNS :</p> <ul> <li>PowerDNS</li> </ul>"},{"location":"guide/terraform/#how-does-it-works","title":"How does it works ?","text":"<pre><code>sequenceDiagram\n    actor User\n    User-&gt;&gt;Packer: Launch Terragrunt command\n    Terraform-&gt;&gt;Hypervisor: Connect to hypervisor API,&lt;br&gt;upload cloud init configuration files&lt;br&gt;and ask hypervisor to create VM with it\n    create participant VM\n    Hypervisor-&gt;&gt;VM: Create and start VM\n    Terraform-&gt;&gt;Terraform: Waiting availability of SSH server\n    Terraform-&gt;&gt;VM: SSH to the VM&lt;br&gt; and wait end of cloud init execution\n    create participant DNS\n    Terraform-&gt;&gt;DNS: Connect to DNS API&lt;br&gt;and create A, AAAA (PTR are optionnals) records</code></pre>"},{"location":"guide/terraform/#usage","title":"Usage","text":"<p>Configuration is stored in <code>terraform</code> folder.</p> <p>Fill <code>account.hcl</code> based on <code>account.example</code>.</p> <pre><code>cd terraform/prod\nterragrunt run-all init\nterragrunt run-all apply\n</code></pre> How to execute only a part of terraform deployment ? <ul> <li> <p>Deploy a group of machine</p> <p>Move over a subdirectory like <code>dhcp</code> and run the same command</p> </li> <li> <p>Deploy one machine in a group</p> <p>Move over a subdirectory like <code>dhcp/dchp1</code> and run the same command</p> </li> </ul>"},{"location":"guide/truenas/","title":"Truenas","text":""},{"location":"guide/truenas/#what-is-truenas","title":"What is Truenas ?","text":"<p>Truenas is a family of network-attached storage (NAS) products produced by iXsystems, incorporating both FOSS, as well as commercial offerings.</p>"},{"location":"guide/truenas/#acme-dns-challenge-with-vault-pki-and-pdns","title":"ACME DNS Challenge with vault PKI and PDNS","text":"<ol> <li>Create a dataset (home directories can't execute scripts see here)</li> <li>Select an user and create an API Key for it</li> <li>Connect to truenas through SSH with your user and execute every action with it (do not use root) and move inside your new dataset</li> <li>Clone acme.sh <code>git clone https://github.com/acmesh-official/acme.sh .acme.sh</code></li> <li>Create an env file <code>/home/&lt;user&gt;/.acme.sh.env</code> with the below contents</li> </ol> <pre><code># PDNS\nPDNS_Url=&lt;TO_REPLACE&gt;\nPDNS_ServerId=localhost\nPDNS_Token=&lt;TO_REPLACE&gt;\nPDNS_Ttl=60\n# PKI CA\nCA_CERT_PATH=/etc/ssl/certs/ca-certificates.crt\n# Truenas\nDEPLOY_TRUENAS_APIKEY=&lt;TO_REPLACE&gt;\nDEPLOY_TRUENAS_SCHEME=https\n</code></pre> <ol> <li>Change your current directory to acme.sh project <code>cd .acme.sh</code></li> <li>Register ACME server <code>./acme.sh --set-default-ca --server &lt;vault_acme_url&gt; --home /home/admin</code> (in my case <code>https://vault.unicornafk.fr:8200/v1/pki/acme/directory</code>)</li> <li>Register DNS issuer <code>./acme.sh --issue --insecure --dns dns_pdns -d &lt;truenas_fqdn&gt; --dnssleep 30 --home /home/admin</code></li> <li>Deploy the certificate <code>./acme.sh -d &lt;truenas_fqdn&gt; --insecure --deploy --deploy-hook truenas --home /home/admin</code></li> <li> <p>Setup cron through the webui</p> </li> <li> <p>Description: ACME.Sh renew certificates</p> </li> <li>User: <code>&lt;user&gt;</code></li> <li>Schedule: Daily</li> <li> <p>Command: <code>. /home/&lt;user&gt;/.acme.sh.env &amp;&amp; \"&lt;dataset path&gt;/.acme.sh\"/acme.sh --issue --dns dns_pdns -d &lt;truenas_fqdn&gt; --dnssleep 30 --insecure --deploy --deploy-hook truenas --ca-bundle /home/admin/ca.crt --home /home/admin</code></p> </li> <li> <p>If you want to check if your cron is successfull run it and check the log with</p> </li> </ol> <pre><code>cat /var/log/syslog | grep -w 'cron'\n</code></pre> <p>!! info \"sudo is broken https://ixsystems.atlassian.net/browse/NAS-131540\"</p>"},{"location":"home/architecture/","title":"Architecture","text":""},{"location":"home/architecture/#networking","title":"Networking","text":"<p>I'm running my own AS for my IPv6 stack registered as AS212510 </p> <ul> <li>Openfactory free BGP Tunnel, thanks to them </li> <li>iFog free BGP Tunnel, thanks to them </li> </ul>"},{"location":"home/architecture/#domains","title":"Domains","text":"<ul> <li>as212510.net for my ASN</li> <li>adminafk.fr for public services</li> <li>unicornafk.fr for internal services</li> </ul>"},{"location":"home/architecture/#cloud-providers","title":"Cloud providers","text":"<ul> <li>Scaleway for domains</li> <li>Infomaniak for S3</li> <li>Proton for emails, VPN</li> <li>Oracle for VPS</li> </ul>"},{"location":"home/choices/","title":"Choices","text":"<p>On this page, I will explain some choices I made as an F.A.Q</p>"},{"location":"home/choices/#why-do-i-use-cloud-services","title":"Why do I use cloud services ?","text":"<ul> <li>Email system is a headhache (blacklist/whitelist etc...) and I don't want to invest time into it</li> <li>Offsite backup (s3 buckets)</li> <li>Disaster recovery, offsite monitoring</li> </ul>"},{"location":"home/choices/#why-did-i-choose-t-bao-mn58u-as-a-server","title":"Why did I choose T-bao MN58U as a server ?","text":"<p>I've replaced my old servers (R320, Homemade with R7 2700) to reduce electricity costs. This server uses only 15W to operate. It is small and doesn't make any noises, and it still has a pretty decent processor with 32Gb RAM.</p>"},{"location":"home/choices/#why-im-using-cloud-european-services","title":"Why I'm using cloud european services ?","text":"<p>My conviction regarding GAFAM and GDPR.</p>"},{"location":"home/choices/#why-do-i-have-an-oracle-vps","title":"Why do I have an Oracle VPS ?","text":"<p>Because this VPS is completely Free with disk encryption otherwise I would have used probably Hetzner like in the past.</p>"}]}